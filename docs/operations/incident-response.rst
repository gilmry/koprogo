========================
Incident Response Plan
========================

:Version: 1.0.0
:Date: 10 novembre 2025

ðŸš¨ Niveaux de SÃ©vÃ©ritÃ©
========================

.. list-table::
   :header-rows: 1
   :widths: 10 30 30 30

   * - Niveau
     - Impact
     - Exemples
     - Response Time
   * - **P0 (Critical)**
     - Service down pour tous
     - API down, DB corruption, security breach
     - < 15 minutes
   * - **P1 (High)**
     - FonctionnalitÃ© majeure down
     - Login fail, paiements bloquÃ©s
     - < 1 heure
   * - **P2 (Medium)**
     - DÃ©gradation performance
     - Latence Ã©levÃ©e, bugs non-bloquants
     - < 4 heures
   * - **P3 (Low)**
     - ProblÃ¨me mineur
     - Typo, UI glitch
     - < 24 heures

ðŸ“ž ProcÃ©dure de RÃ©ponse
========================

Phase 1 : DÃ©tection (0-5 min)
------------------------------

1. **Alerte reÃ§ue** (Alertmanager, user report, monitoring)
2. **Acknowledge** dans Slack #incidents
3. **Ã‰valuer sÃ©vÃ©ritÃ©** (P0-P3)
4. **CrÃ©er incident ticket** (GitHub Issues avec label `incident`)

Phase 2 : Triage (5-15 min)
----------------------------

1. **VÃ©rifier impact** :
   - Combien d'utilisateurs affectÃ©s ?
   - Quelles fonctionnalitÃ©s down ?
   - Risque sÃ©curitÃ©/donnÃ©es ?

2. **Escalader** si nÃ©cessaire :
   - P0 â†’ Notifier Lead Engineer + CTO
   - P1 â†’ Notifier astreinte SRE
   - P2/P3 â†’ Ã‰quipe dev normale

3. **Communication** :
   - P0/P1 : Mettre Ã  jour https://status.koprogo.com
   - Email utilisateurs si prolongÃ© (> 1h)

Phase 3 : RÃ©solution (variable)
--------------------------------

1. **Diagnostiquer** :
   - Consulter logs (Loki)
   - VÃ©rifier mÃ©triques (Grafana)
   - Reproduire si possible

2. **Mitigation immÃ©diate** :
   - Rollback si dÃ©ploiement rÃ©cent
   - Restart service si applicable
   - Activer mode dÃ©gradÃ© si possible

3. **Fix permanent** :
   - DÃ©ployer hotfix
   - Tester en staging first
   - DÃ©ployer en production

Phase 4 : Post-Incident (< 48h)
--------------------------------

1. **Post-mortem meeting** (obligatoire pour P0/P1)
2. **Documentation** :
   - Timeline des Ã©vÃ©nements
   - Root cause analysis (5 Whys)
   - Action items pour prÃ©venir rÃ©currence
3. **Mettre Ã  jour runbooks**

ðŸ” Incidents de SÃ©curitÃ©
==========================

**ProcÃ©dure spÃ©ciale** :

1. **Isolation** : Bloquer trafic si nÃ©cessaire
2. **Forensics** : PrÃ©server logs, snapshots
3. **Notification GDPR** : CNIL sous 72h si breach
4. **Communication** : Transparent avec utilisateurs
5. **Investigation** : Root cause + patch vulnÃ©rabilitÃ©s

ðŸ“‹ Templates
=============

Incident Report
---------------

.. code-block:: markdown

   # Incident Report - [YYYY-MM-DD]

   **Severity**: P0/P1/P2/P3
   **Duration**: HH:MM start â†’ HH:MM resolved
   **Impact**: [Number of users/services affected]

   ## Timeline
   - 14:30 - Alert fired: API P99 > 5s
   - 14:32 - Incident acknowledged
   - 14:35 - Root cause identified: DB connection pool exhausted
   - 14:40 - Mitigation: Restarted API service
   - 14:45 - Resolved: Latency back to normal

   ## Root Cause
   Database connection pool size (10) insufficient under peak load.

   ## Action Items
   - [ ] Increase connection pool to 20
   - [ ] Add alert for connection pool usage > 80%
   - [ ] Load test with realistic traffic

Status Page Update
------------------

.. code-block:: text

   ðŸ”´ **Investigating** - We are currently investigating issues with login functionality.
   Posted: 2025-11-10 14:30 UTC

   ðŸŸ¡ **Identified** - The issue has been identified as a database connection problem.
   Posted: 2025-11-10 14:35 UTC

   ðŸŸ¢ **Resolved** - The login functionality has been restored.
   Posted: 2025-11-10 14:45 UTC

---

**Version** : 1.0.0
