===================================
Disaster Recovery Plan
===================================

:Version: 1.0.0
:Date: 10 novembre 2025
:Public: SRE, DevOps, SysAdmin
:RTO: 4 heures (Recovery Time Objective)
:RPO: 24 heures (Recovery Point Objective)

üìã Vue d'ensemble
=================

Ce runbook d√©crit les proc√©dures de r√©cup√©ration en cas de **d√©faillance critique** des services KoproGo.

**Sc√©narios couverts** :

1. ‚úÖ Corruption de base de donn√©es PostgreSQL
2. ‚úÖ Perte de serveur OVH (panne mat√©rielle, incendie datacenter)
3. ‚úÖ Corruption du filesystem (donn√©es applicatives)
4. ‚úÖ Attaque ransomware / intrusion malveillante
5. ‚úÖ Suppression accidentelle de donn√©es

üéØ Objectifs de R√©cup√©ration
==============================

.. list-table::
   :header-rows: 1
   :widths: 30 20 20 30

   * - Service
     - RTO
     - RPO
     - Priorit√©
   * - API Backend
     - 2h
     - 24h
     - Critique
   * - Base de donn√©es
     - 4h
     - 24h
     - Critique
   * - Frontend (statique)
     - 1h
     - 0h (CDN)
     - Haute
   * - Monitoring
     - 8h
     - 7d
     - Moyenne

üìä Architecture de Sauvegarde
===============================

**Composants sauvegard√©s** :

1. **PostgreSQL** : Dumps quotidiens + WAL archiving
2. **Uploads** : Fichiers utilisateurs (documents, factures)
3. **Configuration** : Variables d'environnement, secrets
4. **Monitoring** : M√©triques Prometheus (30 jours), logs Loki (7 jours)

**Strat√©gie 3-2-1** :

- **3** copies : Production + Backup local + Backup S3
- **2** m√©dias : Disque local (LUKS chiffr√©) + Cloud (S3 chiffr√©)
- **1** copie hors site : OVH Object Storage (Gravelines) ou AWS S3

**R√©tention** :

- Backups quotidiens : **7 jours** (local)
- Backups hebdomadaires : **4 semaines** (S3)
- Backups mensuels : **12 mois** (S3, Glacier)

üì¶ Backups Existants
=====================

Emplacement des sauvegardes
----------------------------

**Local (VPS)** :

- **PostgreSQL dumps** : ``/var/backups/postgresql/``
- **Uploads** : ``/var/backups/uploads/``
- **Config** : ``/var/backups/config/``

**S3 (Off-site)** :

- **Bucket** : ``koprogo-backups-prod``
- **R√©gion** : ``eu-west-3`` (Paris) ou ``eu-north-1`` (Stockholm)
- **Chiffrement** : GPG avec cl√© publique/priv√©e (4096 bits RSA)
- **Lifecycle** : Transition vers Glacier apr√®s 90 jours

V√©rification des backups
-------------------------

**Commande quotidienne** (cron) :

.. code-block:: bash

   #!/bin/bash
   # /opt/koprogo/scripts/verify-backups.sh

   # V√©rifier pr√©sence backup PostgreSQL < 25h
   LATEST_PG_BACKUP=$(find /var/backups/postgresql -name "*.sql.gpg" -mtime -1 | wc -l)
   if [ "$LATEST_PG_BACKUP" -eq 0 ]; then
       echo "‚ùå CRITICAL: No PostgreSQL backup in last 24h"
       exit 1
   fi

   # V√©rifier backup S3
   aws s3 ls s3://koprogo-backups-prod/postgresql/ --recursive | tail -n 5

   # Tester d√©chiffrement (sans restaurer)
   gpg --decrypt /var/backups/postgresql/latest.sql.gpg > /dev/null 2>&1
   if [ $? -eq 0 ]; then
       echo "‚úÖ Backup decryption test successful"
   else
       echo "‚ùå CRITICAL: Backup decryption failed"
       exit 1
   fi

**Alertes** : Slack/Email via Alertmanager si √©chec

üö® Sc√©narios de R√©cup√©ration
==============================

Sc√©nario 1 : Corruption PostgreSQL
-----------------------------------

**Sympt√¥mes** :

- Erreurs "could not read block" dans les logs
- Requ√™tes SQL qui √©chouent avec "invalid page header"
- `pg_dump` √©choue avec erreurs de corruption

**Proc√©dure de r√©cup√©ration** :

.. code-block:: bash

   # 1. Arr√™ter PostgreSQL imm√©diatement
   sudo systemctl stop postgresql

   # 2. Sauvegarder l'√©tat actuel (forensic)
   sudo tar czf /tmp/postgres-corrupted-$(date +%Y%m%d-%H%M%S).tar.gz /var/lib/postgresql/15/main

   # 3. Identifier le backup le plus r√©cent
   LATEST_BACKUP=$(ls -t /var/backups/postgresql/*.sql.gpg | head -n 1)
   echo "Latest backup: $LATEST_BACKUP"

   # 4. D√©chiffrer le backup
   gpg --decrypt $LATEST_BACKUP > /tmp/koprogo_restore.sql

   # 5. Recr√©er la base de donn√©es
   sudo -u postgres dropdb koprogo_db
   sudo -u postgres createdb koprogo_db

   # 6. Restaurer le dump
   sudo -u postgres psql koprogo_db < /tmp/koprogo_restore.sql

   # 7. V√©rifier int√©grit√©
   sudo -u postgres psql koprogo_db -c "SELECT COUNT(*) FROM buildings;"

   # 8. Red√©marrer PostgreSQL
   sudo systemctl start postgresql

   # 9. Tester l'API
   curl http://localhost:8080/health

**Temps estim√©** : 2-4 heures (selon taille DB)

**Perte de donn√©es** : Jusqu'√† 24h (RPO)

Sc√©nario 2 : Perte Totale du Serveur
-------------------------------------

**Sympt√¥mes** :

- Serveur inaccessible (ping fail, SSH timeout)
- Datacenter OVH signale panne mat√©rielle
- Aucune r√©ponse API/Frontend

**Proc√©dure de r√©cup√©ration** :

.. code-block:: bash

   # 1. Provisionner nouveau serveur OVH (Terraform)
   cd infrastructure/terraform
   terraform apply -var="server_name=koprogo-prod-new"

   # 2. Installer stack de base (Ansible)
   cd ../ansible
   ansible-playbook -i inventory.ini playbook.yml

   # 3. R√©cup√©rer backups depuis S3
   aws s3 sync s3://koprogo-backups-prod/postgresql/ /var/backups/postgresql/
   aws s3 sync s3://koprogo-backups-prod/uploads/ /var/backups/uploads/

   # 4. Restaurer PostgreSQL (voir Sc√©nario 1)
   # ...

   # 5. Restaurer uploads
   sudo mkdir -p /opt/koprogo/uploads
   sudo tar xzf /var/backups/uploads/latest.tar.gz -C /opt/koprogo/uploads

   # 6. Restaurer configuration
   sudo cp /var/backups/config/.env /opt/koprogo/backend/.env

   # 7. D√©ployer application (Docker Compose)
   cd /opt/koprogo
   docker-compose up -d

   # 8. Mettre √† jour DNS (A record vers nouvelle IP)
   # Via interface OVH ou Cloudflare

   # 9. V√©rifier services
   curl https://api.koprogo.com/health
   curl https://app.koprogo.com

**Temps estim√©** : 4-6 heures

**Perte de donn√©es** : Jusqu'√† 24h (RPO)

Sc√©nario 3 : Suppression Accidentelle de Donn√©es
-------------------------------------------------

**Sympt√¥mes** :

- Utilisateur signale : "Mes donn√©es ont disparu"
- Logs audit montrent ``DELETE`` inattendu
- V√©rification manuelle confirme absence de donn√©es

**Proc√©dure de r√©cup√©ration** :

.. code-block:: bash

   # 1. Identifier l'heure de suppression (audit logs)
   sudo -u postgres psql koprogo_db -c \
       "SELECT * FROM audit_logs WHERE action='DELETE' AND entity_type='Building' ORDER BY timestamp DESC LIMIT 10;"

   # 2. Choisir le backup AVANT la suppression
   # Exemple : suppression √† 14h30, utiliser backup de 02h00 (m√™me jour)
   BACKUP_FILE="/var/backups/postgresql/koprogo_20251110_020000.sql.gpg"

   # 3. Cr√©er DB temporaire pour extraction
   sudo -u postgres createdb koprogo_temp

   # 4. Restaurer dans DB temp
   gpg --decrypt $BACKUP_FILE | sudo -u postgres psql koprogo_temp

   # 5. Extraire les donn√©es perdues
   sudo -u postgres psql koprogo_temp -c \
       "COPY (SELECT * FROM buildings WHERE id='<building-uuid>') TO '/tmp/lost_building.csv' CSV HEADER;"

   # 6. R√©ins√©rer dans DB production
   sudo -u postgres psql koprogo_db -c \
       "INSERT INTO buildings SELECT * FROM temp_buildings_import ON CONFLICT DO NOTHING;"

   # 7. V√©rifier avec l'utilisateur
   curl -H "Authorization: Bearer <token>" https://api.koprogo.com/api/v1/buildings/<building-uuid>

   # 8. Nettoyer DB temporaire
   sudo -u postgres dropdb koprogo_temp

**Temps estim√©** : 30 minutes - 2 heures

**Perte de donn√©es** : Minimale (donn√©es entre backup et suppression)

Sc√©nario 4 : Attaque Ransomware
--------------------------------

**Sympt√¥mes** :

- Fichiers chiffr√©s avec extension ``.locked`` ou ``.encrypted``
- Note de ran√ßon dans ``/tmp/README_DECRYPT.txt``
- PostgreSQL inaccessible
- Monitoring/alertes satur√©s

**Proc√©dure de r√©cup√©ration** :

.. code-block:: bash

   # 1. ISOLATION IMM√âDIATE
   sudo iptables -A INPUT -j DROP    # Bloquer toute entr√©e
   sudo iptables -A OUTPUT -j DROP   # Bloquer toute sortie
   # Exception : SSH depuis IP admin uniquement

   # 2. ANALYSE FORENSIC
   sudo find / -name "*.locked" -o -name "*.encrypted" | head -n 20
   sudo journalctl --since "1 hour ago" | grep -i "encrypted\|ransom\|locked"

   # 3. NE PAS PAYER LA RAN√áON

   # 4. R√©cup√©ration depuis backups S3 (hors ligne, non compromis)
   # Depuis une machine PROPRE (pas le serveur infect√©)
   aws s3 sync s3://koprogo-backups-prod/ /mnt/recovery/

   # 5. Provisionner NOUVEAU serveur (ne PAS r√©utiliser l'infect√©)
   # Voir Sc√©nario 2 (Perte totale serveur)

   # 6. Enqu√™te de s√©curit√©
   # - Identifier vecteur d'attaque (logs Suricata, fail2ban)
   # - Patcher vuln√©rabilit√©s
   # - Changer TOUS les mots de passe et secrets
   # - R√©voquer toutes les cl√©s SSH

   # 7. Notifier autorit√©s et utilisateurs (GDPR)
   # - CNIL (72h max)
   # - Email tous les utilisateurs

**Temps estim√©** : 8-24 heures (forensics + r√©cup√©ration)

**Perte de donn√©es** : Jusqu'√† 24h (RPO)

üß™ Tests de R√©cup√©ration
=========================

Tests trimestriels obligatoires
--------------------------------

**Q1, Q2, Q3, Q4** : Simuler un sc√©nario de DR complet

**Proc√©dure de test** :

.. code-block:: bash

   # 1. Cr√©er environnement de test (isol√© de prod)
   cd infrastructure/terraform
   terraform apply -var="environment=dr-test"

   # 2. R√©cup√©rer backup S3 le plus r√©cent
   aws s3 cp s3://koprogo-backups-prod/postgresql/latest.sql.gpg /tmp/

   # 3. Restaurer dans environnement de test
   gpg --decrypt /tmp/latest.sql.gpg | psql <test-db-url>

   # 4. D√©ployer application
   docker-compose -f docker-compose.test.yml up -d

   # 5. V√©rifier fonctionnalit√©s critiques
   curl http://test-server/health
   curl http://test-server/api/v1/buildings

   # 6. Mesurer temps de r√©cup√©ration
   # Objectif : < 4h RTO

   # 7. Documenter r√©sultats
   echo "DR Test $(date): RTO actual = 3h 15min ‚úÖ" >> /docs/dr-test-log.txt

   # 8. D√©truire environnement de test
   terraform destroy -var="environment=dr-test"

**Checklist de validation** :

- [ ] Backup d√©chiffr√© avec succ√®s
- [ ] Base de donn√©es restaur√©e compl√®tement
- [ ] API r√©pond √† ``/health``
- [ ] Authentification fonctionnelle (login)
- [ ] Au moins 1 requ√™te CRUD r√©ussie par endpoint principal
- [ ] RTO < 4h respect√©
- [ ] Aucune corruption de donn√©es d√©tect√©e

üìû Contacts d'Urgence
======================

**√âquipe technique** :

- **SRE Lead** : +32 XXX XX XX XX (astreinte 24/7)
- **DBA** : +32 XXX XX XX XX
- **Security Lead** : +32 XXX XX XX XX

**Fournisseurs** :

- **OVH Support** : +33 9 72 10 10 07 (24/7)
- **AWS Support** : https://console.aws.amazon.com/support (Enterprise plan)

**L√©gal** :

- **Avocat** : +32 XXX XX XX XX
- **CNIL (GDPR)** : https://www.cnil.fr/

**Communication** :

- **Slack #incident** : https://koprogo.slack.com/archives/incident
- **Email incidents** : incidents@koprogo.com
- **Status page** : https://status.koprogo.com

üîí S√©curit√© des Cl√©s GPG
==========================

Gestion des cl√©s de chiffrement
--------------------------------

**Cl√© publique** (chiffrement backups) :

- Stock√©e sur serveur : ``/root/.gnupg/pubring.kbx``
- Backup copie publique dans repo Git (s√©curis√©)

**Cl√© priv√©e** (d√©chiffrement backups) :

- **NE PAS stocker sur serveur de production** (risque ransomware)
- Stock√©e hors ligne :
  - Yubikey (SRE Lead)
  - Coffre-fort physique (si√®ge ASBL)
  - Password manager √©quipe (Bitwarden/1Password)

**Rotation des cl√©s** : Annuelle (janvier)

.. code-block:: bash

   # G√©n√©rer nouvelle paire de cl√©s
   gpg --full-generate-key --expert

   # Exporter cl√© publique
   gpg --export -a "KoproGo Backup <backup@koprogo.com>" > koprogo-backup-2026.asc

   # Mettre √† jour sur serveur
   scp koprogo-backup-2026.asc root@prod-server:/root/.gnupg/
   ssh root@prod-server "gpg --import /root/.gnupg/koprogo-backup-2026.asc"

   # Tester chiffrement
   echo "test" | gpg --encrypt --recipient "backup@koprogo.com" | gpg --decrypt

üìã Checklist Post-Incident
============================

Apr√®s chaque r√©cup√©ration
--------------------------

- [ ] **Documenter incident** : Date, cause, proc√©dure suivie, temps r√©el
- [ ] **Post-mortem meeting** : √âquipe technique + stakeholders
- [ ] **Identifier cause racine** : 5 Whys analysis
- [ ] **Mettre √† jour runbook** : Am√©liorer proc√©dures
- [ ] **Notifier utilisateurs** : Email transparent + compensation si applicable
- [ ] **Am√©liorer monitoring** : Ajouter alertes pr√©ventives
- [ ] **Tester √† nouveau** : Re-tester proc√©dure am√©lior√©e dans 30 jours

---

**Version** : 1.0.0 | **Derni√®re mise √† jour** : 10 novembre 2025 | **Prochain test DR** : Janvier 2026
